{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso:\n",
    "\n",
    "Función para evaluar y visualizar el rendimiento de modelos de Machine Learning de manera rápida y eficiente. \n",
    "\n",
    "Eval Model permite tener una visión clara y detallada de cómo se desempeña un modelo en distintos aspectos, ya sea en tareas de regresión o clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(target, predictions, problem_type, metrics):\n",
    "    \"\"\"\n",
    "    Evalúa el rendimiento de un modelo de Machine Learning según las métricas especificadas.\n",
    "    \n",
    "    Argumentos:\n",
    "    target: Lista de valores reales del target.\n",
    "    predictions: Lista de valores predichos por el modelo.\n",
    "    problem_type (str): Tipo de problema ('regression' o 'classification').\n",
    "    metrics: Lista de métricas a calcular.\n",
    "    \n",
    "    Retorna:\n",
    "    tuple: Tupla con los valores de las métricas en el orden de aparición en la lista de entrada.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Funciones auxiliares para las métricas de regresión\n",
    "    def calculate_rmse(target, predictions):\n",
    "        return np.sqrt(mean_squared_error(target, predictions))\n",
    "    \n",
    "    def calculate_mae(target, predictions):\n",
    "        return mean_absolute_error(target, predictions)\n",
    "    \n",
    "    def calculate_mape(target, predictions):\n",
    "        if np.any(target == 0):\n",
    "            raise ValueError(\"MAPE no se puede calcular con valores de target igual a 0\")\n",
    "        return np.mean(np.abs((target - predictions) / target)) * 100\n",
    "    \n",
    "    # Funciones auxiliares para métricas de clasificación\n",
    "    def calculate_accuracy(target, predictions):\n",
    "        return accuracy_score(target, predictions)\n",
    "    \n",
    "    def calculate_precision(target, predictions, average='macro'):\n",
    "        return precision_score(target, predictions, average=average)\n",
    "    \n",
    "    def calculate_recall(target, predictions, average='macro'):\n",
    "        return recall_score(target, predictions, average=average)\n",
    "    \n",
    "    # Procesamiento de métricas según el tipo de problema\n",
    "    if problem_type == 'regression':\n",
    "        for metric in metrics:\n",
    "            if metric == 'RMSE':\n",
    "                rmse = calculate_rmse(target, predictions)\n",
    "                print(f\"RMSE: {rmse}\")\n",
    "                results.append(rmse)\n",
    "            elif metric == 'MAE':\n",
    "                mae = calculate_mae(target, predictions)\n",
    "                print(f\"MAE: {mae}\")\n",
    "                results.append(mae)\n",
    "            elif metric == 'MAPE':\n",
    "                try:\n",
    "                    mape = calculate_mape(target, predictions)\n",
    "                    print(f\"MAPE: {mape}\")\n",
    "                    results.append(mape)\n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "            elif metric == 'GRAPH':\n",
    "                plt.scatter(target, predictions)\n",
    "                plt.xlabel('Actual')\n",
    "                plt.ylabel('Predicted')\n",
    "                plt.title('Actual vs Predicted')\n",
    "                plt.show()\n",
    "    \n",
    "    elif problem_type == 'classification':\n",
    "        for metric in metrics:\n",
    "            if metric == 'ACCURACY':\n",
    "                accuracy = calculate_accuracy(target, predictions)\n",
    "                print(f\"Accuracy: {accuracy}\")\n",
    "                results.append(accuracy)\n",
    "            elif metric == 'PRECISION':\n",
    "                precision = calculate_precision(target, predictions)\n",
    "                print(f\"Precision: {precision}\")\n",
    "                results.append(precision)\n",
    "            elif metric == 'RECALL':\n",
    "                recall = calculate_recall(target, predictions)\n",
    "                print(f\"Recall: {recall}\")\n",
    "                results.append(recall)\n",
    "            elif metric == 'CLASS_REPORT':\n",
    "                report = classification_report(target, predictions)\n",
    "                print(\"Classification Report:\\n\", report)\n",
    "            elif metric == 'MATRIX':\n",
    "                matrix = confusion_matrix(target, predictions)\n",
    "                display = ConfusionMatrixDisplay(confusion_matrix=matrix)\n",
    "                display.plot()\n",
    "                plt.show()\n",
    "            elif metric == 'MATRIX_RECALL':\n",
    "                display = ConfusionMatrixDisplay.from_predictions(target, predictions, normalize='true')\n",
    "                display.plot()\n",
    "                plt.show()\n",
    "            elif metric == 'MATRIX_PRED':\n",
    "                display = ConfusionMatrixDisplay.from_predictions(target, predictions, normalize='pred')\n",
    "                display.plot()\n",
    "                plt.show()\n",
    "            elif 'PRECISION_' in metric:\n",
    "                class_label = metric.split('_')[1]\n",
    "                precision = precision_score(target, predictions, labels=[class_label], average='macro', zero_division=0)\n",
    "                if precision == 0:\n",
    "                    raise ValueError(f\"Etiqueta {class_label} no encontrada en target\")\n",
    "                print(f\"Precision for class {class_label}: {precision}\")\n",
    "                results.append(precision)\n",
    "            elif 'RECALL_' in metric:\n",
    "                class_label = metric.split('_')[1]\n",
    "                recall = recall_score(target, predictions, labels=[class_label], average='macro', zero_division=0)\n",
    "                if recall == 0:\n",
    "                    raise ValueError(f\"Etiqueta {class_label} no encontrada en target\")\n",
    "                print(f\"Recall for class {class_label}: {recall}\")\n",
    "                results.append(recall)\n",
    "    \n",
    "    return tuple(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso:\n",
    "Especialmente útil en problemas de clasificación donde se quiere entender que características numéricas pueden influir en la variable objetivo categórica.\n",
    "\n",
    "Permite enfocarse en aquellas columnas numéricas que tienen una relación estadísticamente significativa con la columna objetivo categórica, facilitando así el proceso de construcción de modelos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_features_num_classification(df, target_col, pvalue=0.05):\n",
    "    \"\"\"\n",
    "    Selecciona columnas numéricas cuyo ANOVA con la columna target supere un nivel de significación.\n",
    "    \n",
    "    Argumentos:\n",
    "    df (pd.DataFrame): DataFrame de entrada.\n",
    "    target_col (str): Nombre de la columna target.\n",
    "    pvalue (float): Nivel de significación para el test de ANOVA. Por defecto 0.05.\n",
    "    \n",
    "    Retorna:\n",
    "    list: Lista de columnas numéricas que cumplen con el criterio de ANOVA.\n",
    "    \"\"\"\n",
    "    # Comprobaciones de los argumentos de entrada\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        print(\"El argumento 'df' no es un DataFrame.\")\n",
    "        return None\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"La columna '{target_col}' no existe en el DataFrame.\")\n",
    "        return None\n",
    "    if not pd.api.types.is_categorical_dtype(df[target_col]) and not pd.api.types.is_object_dtype(df[target_col]):\n",
    "        print(f\"La columna '{target_col}' no es categórica.\")\n",
    "        return None\n",
    "    if not isinstance(pvalue, float) or not (0 < pvalue < 1):\n",
    "        print(\"El argumento 'pvalue' debe ser un float entre 0 y 1.\")\n",
    "        return None\n",
    "    \n",
    "    # Convertir target_col a categórica si no lo es\n",
    "    if not pd.api.types.is_categorical_dtype(df[target_col]):\n",
    "        df[target_col] = df[target_col].astype('category')\n",
    "    \n",
    "    # Filtrar columnas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=[float, int]).columns.tolist()\n",
    "    significant_features = []\n",
    "    \n",
    "    # Realizar el test ANOVA\n",
    "    for col in numeric_cols:\n",
    "        groups = [df[df[target_col] == cat][col].dropna() for cat in df[target_col].cat.categories]\n",
    "        if all(len(group) > 0 for group in groups):\n",
    "            _, p_val = f_oneway(*groups)\n",
    "            if p_val < (1 - pvalue):\n",
    "                significant_features.append(col)\n",
    "    \n",
    "    return significant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso:\n",
    "\n",
    "Esta función la utilizamos para visualizar relaciones entre características numéricas y una variable objetivo categórica en un modelo de clasificación. \n",
    "\n",
    " Tiene como objetivo generar gráficos de pares (pairplots) de columnas numéricas en un DataFrame que muestran una relación significativa con una columna objetivo categórica, utilizando el test ANOVA para evaluar la significancia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_features_num_classification(df, target_col=\"\", columns=[], pvalue=0.05):\n",
    "    \"\"\"\n",
    "    Genera pairplots de columnas numéricas significativas basadas en ANOVA para clasificación.\n",
    "\n",
    "    Esta función toma un DataFrame, una columna objetivo categórica y una lista de columnas numéricas, \n",
    "    y genera pairplots de las columnas numéricas que tienen una relación significativa con la columna \n",
    "    objetivo según el test de ANOVA. Si la lista de columnas está vacía, se consideran todas las columnas \n",
    "    numéricas del DataFrame.\n",
    "\n",
    "    Argumentos:\n",
    "    df (pd.DataFrame): DataFrame de entrada.\n",
    "    target_col (str): Nombre de la columna objetivo categórica.\n",
    "    columns (list): Lista de nombres de columnas numéricas a considerar. Por defecto es una lista vacía.\n",
    "    pvalue (float): Nivel de significación para el test de ANOVA. Por defecto 0.05.\n",
    "\n",
    "    Retorna:\n",
    "    list: Lista de columnas numéricas que cumplen con el criterio de ANOVA.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Verificamos si target_col está en el dataframe\n",
    "    if target_col not in df.columns:\n",
    "        print(\"Error: 'target_col' no está en el dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Verificamos si target_col es categórica\n",
    "    if not pd.api.types.is_categorical_dtype(df[target_col]) and not pd.api.types.is_object_dtype(df[target_col]):\n",
    "        print(\"Error: 'target_col' debe ser una variable categórica.\")\n",
    "        return None\n",
    "    \n",
    "    # Si la lista columns está vacía, tomamos todas las columnas numéricas\n",
    "    if not columns:\n",
    "        columns = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Verificamos si las columnas están en el dataframe y son numéricas\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: La columna '{col}' no está en el dataframe.\")\n",
    "            return None\n",
    "        if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "            print(f\"Error: La columna '{col}' no es numérica.\")\n",
    "            return None\n",
    "\n",
    "    # Filtramos las columnas basándonos en el test de ANOVA\n",
    "    columnas_significativas = []\n",
    "    categorias_target = df[target_col].dropna().unique()\n",
    "    if len(categorias_target) < 2:\n",
    "        print(\"Error: 'target_col' debe tener al menos dos valores únicos.\")\n",
    "        return None\n",
    "\n",
    "    for col in columns:\n",
    "        grupos = [df[df[target_col] == categoria][col].dropna() for categoria in categorias_target]\n",
    "        if len(grupos) > 1 and all(len(grupo) > 1 for grupo in grupos):\n",
    "            estadistico_f, valor_p = f_oneway(*grupos)\n",
    "            if valor_p < pvalue:\n",
    "                columnas_significativas.append(col)\n",
    "\n",
    "    if not columnas_significativas:\n",
    "        print(\"No hay columnas que pasen el test de ANOVA.\")\n",
    "        return []\n",
    "\n",
    "    # Definimos el número de valores por gráfico para las categorías del target\n",
    "    max_valores_target_por_grafico = 5\n",
    "    max_columnas_por_grafico = 5\n",
    "\n",
    "    divisiones_target = [categorias_target[i:i + max_valores_target_por_grafico] for i in range(0, len(categorias_target), max_valores_target_por_grafico)]\n",
    "    divisiones_columnas = [columnas_significativas[i:i + max_columnas_por_grafico] for i in range(0, len(columnas_significativas), max_columnas_por_grafico)]\n",
    "\n",
    "    # Creamos los pairplots\n",
    "    for division_target in divisiones_target:\n",
    "        for division_columnas in divisiones_columnas:\n",
    "            subset_df = df[df[target_col].isin(division_target)]\n",
    "            columnas_para_graficar = division_columnas + [target_col]\n",
    "            sns.pairplot(subset_df[columnas_para_graficar], hue=target_col)\n",
    "            plt.show()\n",
    "\n",
    "    return columnas_significativas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso:\n",
    "\n",
    "Selección de características categóricas en problemas de clasificación, identificando aquellas que tienen una relación significativa con la variable objetivo. \n",
    "\n",
    "La función combina la validación de entradas, codificación de datos y cálculos estadísticos para proporcionar una lista de características significativas que pueden ser utilizadas en la construcción de modelos de clasificación y tambien puede ayudar a reducir el número de características mejorando el rendimiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_cat_classification_2(df, target_col, normalize=False, mi_threshold=0.0):\n",
    "    \"\"\"\n",
    "    Selecciona columnas categóricas cuyo valor de mutual information con la columna target supere un umbral.\n",
    "\n",
    "    Argumentos:\n",
    "    df (pd.DataFrame): DataFrame de entrada.\n",
    "    target_col (str): Nombre de la columna target.\n",
    "    normalize (bool): Si es True, se normaliza el valor de mutual information. Por defecto es False.\n",
    "    mi_threshold (float): Umbral para el valor de mutual information. Por defecto es 0.\n",
    "\n",
    "    Retorna:\n",
    "    list: Lista de columnas categóricas que cumplen con el criterio de mutual information.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Verificamos si target_col está en el dataframe\n",
    "    if target_col not in df.columns:\n",
    "        print(\"Error: 'target_col' no está en el dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Verificamos si target_col es categórica o numérica discreta con baja cardinalidad\n",
    "    if not (pd.api.types.is_categorical_dtype(df[target_col]) or pd.api.types.is_object_dtype(df[target_col]) or \n",
    "            (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() < 20)):\n",
    "        print(\"Error: 'target_col' debe ser una variable categórica o numérica discreta con baja cardinalidad.\")\n",
    "        return None\n",
    "    \n",
    "    # Verificamos si mi_threshold es un float válido\n",
    "    if not isinstance(mi_threshold, float):\n",
    "        print(\"Error: 'mi_threshold' debe ser un valor float.\")\n",
    "        return None\n",
    "\n",
    "    # Si normalize es True, verificamos que mi_threshold esté entre 0 y 1\n",
    "    if normalize and not (0 <= mi_threshold <= 1):\n",
    "        print(\"Error: 'mi_threshold' debe estar entre 0 y 1 cuando 'normalize' es True.\")\n",
    "        return None\n",
    "    \n",
    "    # Convertir columnas categóricas a códigos numéricos\n",
    "    le = LabelEncoder()\n",
    "    df_categorical = df.select_dtypes(include=['category', 'object'])\n",
    "    df_categorical_encoded = df_categorical.apply(lambda x: le.fit_transform(x))\n",
    "    \n",
    "    # Unir las columnas categóricas convertidas con las columnas numéricas originales\n",
    "    df_encoded = pd.concat([df.drop(df_categorical.columns, axis=1), df_categorical_encoded], axis=1)\n",
    "    \n",
    "    # Calculamos la mutual information para las columnas categóricas convertidas\n",
    "    cols_categoricas_encoded = df_categorical_encoded.columns.tolist()\n",
    "    mi_scores = mutual_info_classif(df_encoded[cols_categoricas_encoded], df_encoded[target_col], discrete_features=True)\n",
    "\n",
    "    if normalize:\n",
    "        # Normalizamos los valores de mutual information\n",
    "        mi_scores /= mi_scores.sum()\n",
    "    \n",
    "    # Seleccionamos las columnas que cumplen con el umbral\n",
    "    columnas_significativas = [col for col, mi in zip(cols_categoricas_encoded, mi_scores) if mi >= mi_threshold]\n",
    "\n",
    "    return columnas_significativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USO:\n",
    "\n",
    "La función plot_features_cat_classification genera gráficos de distribución para columnas categóricas que tienen una relación significativa con una columna objetivo (target) basada en el valor de información mutua (mutual information). Este tipo de visualización es útil para entender cómo las categorías de las características categóricas están distribuidas en relación con la variable objetivo.\n",
    "\n",
    "En resumen su objetivo es crear una visualización de las categorías con relación a la variable objetivo. Esto facilita la interpretación de las variables categóricas en un modelo de clasificación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_features_cat_classification(df, target_col=\"\", columns=[], mi_threshold=0.0, normalize=False):\n",
    "    \"\"\"\n",
    "    Genera gráficos de distribución para columnas categóricas significativas basadas en mutual information.\n",
    "\n",
    "    Esta función toma un DataFrame, una columna objetivo categórica y una lista de columnas categóricas, \n",
    "    y genera gráficos de distribución de las columnas categóricas que tienen una relación significativa con la columna \n",
    "    objetivo según el valor de mutual information. Si la lista de columnas está vacía, se consideran todas las columnas \n",
    "    categóricas del DataFrame.\n",
    "\n",
    "    Argumentos:\n",
    "    df (pd.DataFrame): DataFrame de entrada.\n",
    "    target_col (str): Nombre de la columna objetivo categórica.\n",
    "    columns (list): Lista de nombres de columnas categóricas a considerar. Por defecto es una lista vacía.\n",
    "    mi_threshold (float): Umbral para el valor de mutual information. Por defecto es 0.0.\n",
    "    normalize (bool): Si es True, se normaliza el valor de mutual information. Por defecto es False.\n",
    "\n",
    "    Retorna:\n",
    "    list: Lista de columnas categóricas que cumplen con el criterio de mutual information.\n",
    "    \"\"\"\n",
    "\n",
    "    # Verificamos si target_col está en el dataframe\n",
    "    if target_col not in df.columns:\n",
    "        print(\"Error: 'target_col' no está en el dataframe.\")\n",
    "        return None\n",
    "    \n",
    "    # Verificamos si target_col es categórica o numérica discreta con baja cardinalidad\n",
    "    if not (pd.api.types.is_categorical_dtype(df[target_col]) or pd.api.types.is_object_dtype(df[target_col]) or \n",
    "            (pd.api.types.is_numeric_dtype(df[target_col]) and df[target_col].nunique() < 20)):\n",
    "        print(\"Error: 'target_col' debe ser una variable categórica o numérica discreta con baja cardinalidad.\")\n",
    "        return None\n",
    "    \n",
    "    # Verificamos si mi_threshold es un float válido\n",
    "    if not isinstance(mi_threshold, float):\n",
    "        print(\"Error: 'mi_threshold' debe ser un valor float.\")\n",
    "        return None\n",
    "\n",
    "    # Si normalize es True, verificamos que mi_threshold esté entre 0 y 1\n",
    "    if normalize and not (0 <= mi_threshold <= 1):\n",
    "        print(\"Error: 'mi_threshold' debe estar entre 0 y 1 cuando 'normalize' es True.\")\n",
    "        return None\n",
    "    \n",
    "    # Si la lista columns está vacía, tomamos todas las columnas categóricas\n",
    "    if not columns:\n",
    "        columns = df.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "    \n",
    "    # Verificamos si las columnas están en el dataframe y son categóricas\n",
    "    for col in columns:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: La columna '{col}' no está en el dataframe.\")\n",
    "            return None\n",
    "        if not (pd.api.types.is_categorical_dtype(df[col]) or pd.api.types.is_object_dtype(df[col])):\n",
    "            print(f\"Error: La columna '{col}' no es categórica.\")\n",
    "            return None\n",
    "\n",
    "    # Calculamos la mutual information para las columnas categóricas\n",
    "    mi_scores = mutual_info_classif(df[columns], df[target_col], discrete_features=True)\n",
    "\n",
    "    if normalize:\n",
    "        # Normalizamos los valores de mutual information\n",
    "        mi_scores /= mi_scores.sum()\n",
    "    \n",
    "    # Seleccionamos las columnas que cumplen con el umbral\n",
    "    columnas_significativas = [col for col, mi in zip(columns, mi_scores) if mi >= mi_threshold]\n",
    "\n",
    "    if not columnas_significativas:\n",
    "        print(\"No hay columnas que pasen el umbral de mutual information.\")\n",
    "        return []\n",
    "\n",
    "    # Graficamos la distribución de etiquetas para cada columna significativa\n",
    "    for col in columnas_significativas:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.countplot(data=df, x=col, hue=target_col)\n",
    "        plt.title(f'Distribución de {col} respecto a {target_col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(title=target_col)\n",
    "        plt.show()\n",
    "\n",
    "    return columnas_significativas\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
